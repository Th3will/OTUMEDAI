{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-15T17:11:24.262902Z",
     "iopub.status.busy": "2021-09-15T17:11:24.262476Z",
     "iopub.status.idle": "2021-09-15T17:11:28.058552Z",
     "shell.execute_reply": "2021-09-15T17:11:28.05774Z",
     "shell.execute_reply.started": "2021-09-15T17:11:24.262843Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# import time\n",
    "# from contextlib import contextmanager # timer\n",
    "# from functools import partial\n",
    "import cv2\n",
    "# import seaborn as sns\n",
    "# import SimpleITK as sitk\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "from skimage.transform import rescale, resize\n",
    "from scipy.ndimage import rotate\n",
    "# import torch\n",
    "# from torch.utils import data\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "import SimpleITK as sitk\n",
    "# from skimage import data, img_as_float\n",
    "from skimage import exposure\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T17:11:54.379803Z",
     "iopub.status.busy": "2021-09-15T17:11:54.37945Z",
     "iopub.status.idle": "2021-09-15T17:11:54.386204Z",
     "shell.execute_reply": "2021-09-15T17:11:54.385452Z",
     "shell.execute_reply.started": "2021-09-15T17:11:54.379745Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_generator(batch_size, gen_x): \n",
    "    batch_features = np.zeros((batch_size,256,256,3))\n",
    "    batch_labels = np.zeros((batch_size,256,256,3)) \n",
    "    print(batch_size)\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            batch_features[i] , batch_labels[i] = next(gen_x)\n",
    "        yield batch_features, batch_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T17:11:54.624578Z",
     "iopub.status.busy": "2021-09-15T17:11:54.624342Z",
     "iopub.status.idle": "2021-09-15T17:11:54.648968Z",
     "shell.execute_reply": "2021-09-15T17:11:54.648023Z",
     "shell.execute_reply.started": "2021-09-15T17:11:54.624534Z"
    }
   },
   "outputs": [],
   "source": [
    "def gaussian_noise(img, mean=0, sigma=0.03):\n",
    "    img = img.copy()\n",
    "    noise = np.random.normal(mean, sigma, img.shape)\n",
    "    mask_overflow_upper = img+noise >= 1.0\n",
    "    mask_overflow_lower = img+noise < 0\n",
    "    noise[mask_overflow_upper] = 1.0\n",
    "    noise[mask_overflow_lower] = 0\n",
    "    img += noise\n",
    "    return img\n",
    "\n",
    "#https://towardsdatascience.com/complete-image-augmentation-in-opencv-31a6b02694f5\n",
    "def brightness(img, low, high):\n",
    "    value = random.uniform(low, high)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hsv = np.array(hsv, dtype = np.float64)\n",
    "    hsv[:,:,1] = hsv[:,:,1]*value\n",
    "    hsv[:,:,1][hsv[:,:,1]>255]  = 255\n",
    "    hsv[:,:,2] = hsv[:,:,2]*value \n",
    "    hsv[:,:,2][hsv[:,:,2]>255]  = 255\n",
    "    hsv = np.array(hsv, dtype = np.uint8)\n",
    "    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    return img\n",
    "\n",
    "#https://towardsdatascience.com/complete-image-augmentation-in-opencv-31a6b02694f5\n",
    "def fill(img, h, w):\n",
    "    img = img.astype('float32')\n",
    "    img = cv2.resize(img, (h, w), cv2.INTER_CUBIC)\n",
    "    return img\n",
    "def zoom(img, mask, value):\n",
    "    if value > 1 or value < 0:\n",
    "        print('Value for zoom should be less than 1 and greater than 0')\n",
    "        return img, mask\n",
    "    value = random.uniform(value, 1)\n",
    "    h, w = img.shape[:2]\n",
    "    h_taken = int(value*h)\n",
    "    w_taken = int(value*w)\n",
    "    h_start = random.randint(0, h-h_taken)\n",
    "    w_start = random.randint(0, w-w_taken)\n",
    "    img = img[h_start:h_start+h_taken, w_start:w_start+w_taken, :]\n",
    "    img = fill(img, h, w)\n",
    "    mask = mask[h_start:h_start+h_taken, w_start:w_start+w_taken, :]\n",
    "    mask = fill(mask, h, w)\n",
    "    return img, mask\n",
    "\n",
    "# https://towardsdatascience.com/complete-image-augmentation-in-opencv-31a6b02694f5\n",
    "def vertical_shift(img, mask, ratio=0.0):\n",
    "    if ratio > 1 or ratio < 0:\n",
    "        print('Value should be less than 1 and greater than 0')\n",
    "        return img, mask\n",
    "    ratio = random.uniform(-ratio, ratio)\n",
    "    h, w = img.shape[:2]\n",
    "    to_shift = h*ratio\n",
    "    if ratio > 0:\n",
    "        img = img[:, :int(w-to_shift), :]\n",
    "        mask = mask[:, :int(w-to_shift), :]\n",
    "    if ratio < 0:\n",
    "        img = img[:, int(-1*to_shift):, :]\n",
    "        mask = mask[:, int(-1*to_shift):, :]\n",
    "    img = fill(img, h, w)\n",
    "    mask = fill(mask, h, w)\n",
    "    return img, mask\n",
    "\n",
    "# https://towardsdatascience.com/complete-image-augmentation-in-opencv-31a6b02694f5 \n",
    "def horizontal_shift(img, mask, ratio=0.0):\n",
    "    if ratio > 1 or ratio < 0:\n",
    "        print('Value should be less than 1 and greater than 0')\n",
    "        return img, mask\n",
    "    ratio = random.uniform(-ratio, ratio)\n",
    "    h, w = img.shape[:2]\n",
    "    to_shift = w*ratio\n",
    "    if ratio > 0:\n",
    "        img = img[:, :int(w-to_shift), :]\n",
    "        mask = mask[:, :int(w-to_shift), :]\n",
    "    if ratio < 0:\n",
    "        img = img[:, int(-1*to_shift):, :]\n",
    "        mask = mask[:, int(-1*to_shift):, :]\n",
    "    img = fill(img, h, w)\n",
    "    mask = fill(mask, h, w)\n",
    "    return img,mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T17:16:15.013659Z",
     "iopub.status.busy": "2021-09-15T17:16:15.013302Z",
     "iopub.status.idle": "2021-09-15T17:16:15.034965Z",
     "shell.execute_reply": "2021-09-15T17:16:15.034216Z",
     "shell.execute_reply.started": "2021-09-15T17:16:15.013577Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_data(filelist, img_path, mask_path, gen_type = \"train\"):\n",
    "    while True:\n",
    "        for i in filelist:\n",
    "            X_train = cv2.imread(img_path + i, cv2.IMREAD_COLOR )\n",
    "            X_train = cv2.resize(X_train, (256,256), interpolation= cv2.INTER_LINEAR )\n",
    "            y_mask = cv2.imread(mask_path + i, cv2.IMREAD_COLOR)\n",
    "            y_mask = cv2.resize(y_mask, (256,256), interpolation= cv2.IMREAD_GRAYSCALE)\n",
    "            _,y_mask = cv2.threshold(y_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "            y_train = (y_mask/255).astype(int)\n",
    "            if gen_type == \"train\":\n",
    "                # returns a random integer used to select augmentataion techniques for a given sample\n",
    "                augment_num = np.random.randint(0,9)\n",
    "                if augment_num == 0:\n",
    "                    # do nothing\n",
    "                    X_train = X_train\n",
    "                elif augment_num == 1:\n",
    "                    #random noise\n",
    "                    X_train = X_train + np.random.rand(X_train.shape[0], X_train.shape[1], X_train.shape[2])*np.random.randint(-100,100)\n",
    "                elif augment_num == 2:\n",
    "                    X_train = cv2.GaussianBlur(X_train,(random.randrange(1,50,2),random.randrange(1,50,2)), 0)\n",
    "                elif augment_num == 3:\n",
    "                    rot = np.random.randint(-45,45)\n",
    "                    X_train = rotate(X_train,rot, reshape=False)\n",
    "                    y_train = rotate(y_train,rot, reshape=False)\n",
    "                elif augment_num == 4:\n",
    "                    X_train = brightness(X_train,0.5,3)\n",
    "                elif augment_num == 5:\n",
    "                    X_train = np.fliplr(X_train)\n",
    "                    y_train = np.fliplr(y_train)\n",
    "                elif augment_num == 6:\n",
    "                    X_train = np.flipud(X_train)\n",
    "                    y_train = np.flipud(y_train)\n",
    "                elif augment_num == 7:\n",
    "                    hshift = round(random.uniform(0.1, 0.3),3)\n",
    "                    X_train, y_train = horizontal_shift(X_train, y_train, hshift)\n",
    "                elif augment_num == 8:\n",
    "                    vshift = round(random.uniform(0.1, 0.3),3)\n",
    "                    X_train, y_train = vertical_shift(X_train, y_train, vshift)\n",
    "                elif augment_num == 9:\n",
    "                    zoom_rate = round(random.uniform(0.8, 0.95),3)\n",
    "                    X_train, y_train = zoom(X_train, y_train, zoom_rate)\n",
    "                elif augment_num == 10:\n",
    "                    #contrast\n",
    "                    X_train = exposure.equalize_adapthist(X_train.astype(int), clip_limit=0.03)  \n",
    "                elif augment_num == 11:\n",
    "                    #contrast\n",
    "                    X_train = exposure.equalize_hist(X_train.astype(int))  \n",
    "            yield X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T17:11:55.153629Z",
     "iopub.status.busy": "2021-09-15T17:11:55.153313Z",
     "iopub.status.idle": "2021-09-15T17:11:55.161715Z",
     "shell.execute_reply": "2021-09-15T17:11:55.160741Z",
     "shell.execute_reply.started": "2021-09-15T17:11:55.153543Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_data_pred(filelist, img_path, mask_path, gen_type = \"train\"):\n",
    "    while True:\n",
    "        for i in filelist:\n",
    "            original_img = cv2.imread(img_path + i, cv2.IMREAD_COLOR )\n",
    "            X_train = cv2.resize(original_img, (256,256), interpolation= cv2.INTER_LINEAR )\n",
    "            if gen_type == \"train\":\n",
    "                X_train = X_train * np.random.choice([1,1,1,np.random.rand(256, 256,3)])\n",
    "            original_mask = cv2.imread(mask_path + i, cv2.IMREAD_COLOR)\n",
    "            y_mask = cv2.resize(original_mask, (256,256), interpolation= cv2.IMREAD_GRAYSCALE)\n",
    "            _,y_mask = cv2.threshold(y_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "            y_mask = (y_mask/255).astype(int)\n",
    "            yield original_img, original_mask, X_train, y_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T17:11:55.528494Z",
     "iopub.status.busy": "2021-09-15T17:11:55.528226Z",
     "iopub.status.idle": "2021-09-15T17:11:55.535091Z",
     "shell.execute_reply": "2021-09-15T17:11:55.534296Z",
     "shell.execute_reply.started": "2021-09-15T17:11:55.528448Z"
    }
   },
   "outputs": [],
   "source": [
    "def dice_score(mask_gt, mask_pred):\n",
    "    \"\"\"Computes soerensen-dice coefficient.\n",
    "\n",
    "    compute the soerensen-dice coefficient between the ground truth mask `mask_gt`\n",
    "    and the predicted mask `mask_pred`.\n",
    "\n",
    "    Args:\n",
    "    mask_gt: 3-dim Numpy array of type bool. The ground truth mask.\n",
    "    mask_pred: 3-dim Numpy array of type bool. The predicted mask.\n",
    "\n",
    "    Returns:\n",
    "    the dice coeffcient as float. If both masks are empty, the result is NaN.\n",
    "    \"\"\"\n",
    "    volume_sum = mask_gt.sum() + mask_pred.sum()\n",
    "    if volume_sum == 0:\n",
    "        return np.NaN\n",
    "    volume_intersect = (mask_gt & mask_pred).sum()\n",
    "    return 2*volume_intersect / volume_sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T17:11:56.117012Z",
     "iopub.status.busy": "2021-09-15T17:11:56.11671Z",
     "iopub.status.idle": "2021-09-15T17:11:57.826458Z",
     "shell.execute_reply": "2021-09-15T17:11:57.825682Z",
     "shell.execute_reply.started": "2021-09-15T17:11:56.116961Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "# From: https://gist.github.com/wassname/7793e2058c5c9dacb5212c0ac0b18a8a\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "    \"\"\"\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T17:11:57.828665Z",
     "iopub.status.busy": "2021-09-15T17:11:57.828344Z",
     "iopub.status.idle": "2021-09-15T17:11:57.840762Z",
     "shell.execute_reply": "2021-09-15T17:11:57.839978Z",
     "shell.execute_reply.started": "2021-09-15T17:11:57.828613Z"
    }
   },
   "outputs": [],
   "source": [
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "\n",
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    return 1-jacard_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T17:11:57.842749Z",
     "iopub.status.busy": "2021-09-15T17:11:57.842212Z",
     "iopub.status.idle": "2021-09-15T17:11:57.894824Z",
     "shell.execute_reply": "2021-09-15T17:11:57.894194Z",
     "shell.execute_reply.started": "2021-09-15T17:11:57.8427Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def get_model(img_size, num_classes):\n",
    "\n",
    "    inputs = tf.keras.Input(shape=img_size + (3,))\n",
    "    #inputs = tf.keras.Input(shape=(256,256,3))\n",
    "    #inputs = tf.keras.Input(shape=img_size + (1,))\n",
    "    ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "    for filters in [64, 128, 256]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "    for filters in [256, 128, 64, 32]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Add a per-pixel classification layer\n",
    "    outputs = layers.Conv2D(num_classes, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=jacard_coef_loss, metrics = [jacard_coef, dice_coef])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Build model\n",
    "#model = get_model(img_size, num_classes)\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T17:11:57.896302Z",
     "iopub.status.busy": "2021-09-15T17:11:57.896036Z",
     "iopub.status.idle": "2021-09-15T17:11:57.904436Z",
     "shell.execute_reply": "2021-09-15T17:11:57.902083Z",
     "shell.execute_reply.started": "2021-09-15T17:11:57.896255Z"
    }
   },
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.1, patience=3, verbose=1, mode='min',\n",
    "    min_delta=0.0001, cooldown=5, min_lr=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env SM_FRAMEWORK=tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T17:12:05.147179Z",
     "iopub.status.busy": "2021-09-15T17:12:05.146865Z",
     "iopub.status.idle": "2021-09-15T17:12:05.170621Z",
     "shell.execute_reply": "2021-09-15T17:12:05.170013Z",
     "shell.execute_reply.started": "2021-09-15T17:12:05.147131Z"
    }
   },
   "outputs": [],
   "source": [
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T17:12:25.749488Z",
     "iopub.status.busy": "2021-09-15T17:12:25.749202Z",
     "iopub.status.idle": "2021-09-15T17:12:25.995238Z",
     "shell.execute_reply": "2021-09-15T17:12:25.994523Z",
     "shell.execute_reply.started": "2021-09-15T17:12:25.749435Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "import time\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = np.asarray(os.listdir(\"../training/images/\"))\n",
    "image_path = \"../training/images/\" \n",
    "mask_path = \"../training/masks/\"\n",
    "\n",
    "checkpoint_path = \"./Kidney_Check/\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# run = neptune.init(project='SSCP/HyperKvasir',\n",
    "                #    api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIzMGUyN2Q2ZS05MjVkLTRlMzItODYwZS0yODQ3ZWU3ZTdmMmEifQ==') # your credentials\n",
    "\n",
    "\n",
    "batchsize = 1\n",
    "data_size = len(file_list)\n",
    "num_epoch = 30\n",
    "splits = 10\n",
    "kf = KFold(n_splits=splits)\n",
    "valsize = data_size // splits\n",
    "trainsize = data_size - valsize\n",
    "my_model = \"efficientnetb1\"\n",
    "data_num = np.arange(data_size)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1\n",
    "                                                 )\n",
    "# for train_index, val_index in kf.split(data_num):\n",
    "#     print(train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T17:16:19.377694Z",
     "iopub.status.busy": "2021-09-15T17:16:19.377247Z",
     "iopub.status.idle": "2021-09-15T17:18:56.893837Z",
     "shell.execute_reply": "2021-09-15T17:18:56.892616Z",
     "shell.execute_reply.started": "2021-09-15T17:16:19.377621Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "img_size = (256, 256)\n",
    "num_classes = 3\n",
    "\n",
    "# run[\"Dataset\"] = \"Polyp\"\n",
    "# run[\"Model\"] = my_model\n",
    "# run[\"CV-folds\"] = splits\n",
    "# run[\"Epochs\"] = num_epoch\n",
    "# run[\"Batch size\"] = batchsize\n",
    "# run[\"pretrained\"] = \"Imagenet\"\n",
    "# ##########################################################################################\n",
    "# # Check what augmentation techniques you use and say \"yes\" or \"no\" in the fields bellow  #\n",
    "# # You can also add new fields                                                            #\n",
    "# ##########################################################################################\n",
    "# run[\"noise\"] = \"yes\"\n",
    "# run[\"blurring\"] = \"yes\"\n",
    "# run[\"cropping\"] = \"no\"\n",
    "# run[\"flipping\"] = \"yes\"\n",
    "# run[\"rotation\"] = \"yes\"\n",
    "# run[\"zoom\"] = \"yes\"\n",
    "# run[\"translation\"] = \"no\"\n",
    "# run[\"brightness\"] = \"yes\"\n",
    "# run[\"contrast_hist\"] = \"no\"\n",
    "# run[\"contrast_adaptive\"] = \"no\"\n",
    "# run[\"color augmentation\"] = \"no\"\n",
    "# run[\"saturation\"] =\"no\"\n",
    "# run[\"horizontal shift\"] = \"yes\"\n",
    "# run[\"vertical shift\"] = \"yes\"\n",
    "\n",
    "validation_dice_original = np.zeros([valsize,splits])\n",
    "validation_dice_resized = np.zeros([valsize,splits])\n",
    "#validation_jaccard_original = np.zeros([valsize,splits])\n",
    "#validation_jaccard_resized = np.zeros([valsize,splits])\n",
    "training_indexes = [] \n",
    "validation_indexes = []\n",
    "for train_index, val_index in kf.split(data_num):\n",
    "    training_indexes.append(train_index)\n",
    "    validation_indexes.append(val_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"counter.txt\", \"r\")\n",
    "cv_count = int(f.read())\n",
    "f.close()\n",
    "print(cv_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Unet(my_model, encoder_weights='imagenet', input_shape=( 256,256, 3), classes=3, activation='sigmoid')\n",
    "#model.load_weights(checkpoint_path)\n",
    "model.compile(optimizer='Adam', loss=jacard_coef_loss, metrics = [jacard_coef, dice_coef])\n",
    "\n",
    "train = True\n",
    "\n",
    "\n",
    "\n",
    "while(0 <= cv_count < 10 and train == True):\n",
    "    train_index = training_indexes[cv_count]\n",
    "    val_index = validation_indexes[cv_count]\n",
    "    model.fit(x=batch_generator(batchsize, generate_data(file_list[train_index], image_path, mask_path, gen_type = \"train\")), epochs=num_epoch, \n",
    "                            steps_per_epoch=(trainsize/batchsize), \n",
    "                            validation_steps=(valsize/batchsize),\n",
    "                            validation_data=batch_generator(batchsize, generate_data(file_list[val_index], image_path, mask_path, gen_type = \"val\")), \n",
    "                            validation_freq=1, \n",
    "                            verbose = 1, \n",
    "                            callbacks=[reduce_lr,cp_callback],\n",
    "                            )\n",
    "    val_gen  = generate_data_pred(file_list[val_index], image_path, mask_path, gen_type = \"val\")\n",
    "    for i in range(valsize):\n",
    "        time_start = time.time()\n",
    "        original_img, original_mask, X, y_true = next(val_gen)\n",
    "        original_shape = original_img.shape\n",
    "        y_pred = model.predict(np.expand_dims(X,0))\n",
    "        _,y_pred_thr = cv2.threshold(y_pred[0,:,:,0]*255, 127, 255, cv2.THRESH_BINARY)\n",
    "        y_pred = (y_pred_thr/255).astype(int)\n",
    "        dice_resized = dice_score(y_true[:,:,0],y_pred)\n",
    "        #jaccard_resized = jaccard_score(y_true[:,:,0],y_pred, average=\"macro\")\n",
    "        \n",
    "        y_pred_original = cv2.resize(y_pred.astype(float), (original_shape[1],original_shape[0]), interpolation= cv2.INTER_LINEAR)\n",
    "        dice_original = dice_score(original_mask[:,:,0],y_pred_original.astype(int)*255)\n",
    "        #jaccard_original = jaccard_score(original_mask[:,:,0],y_pred_original.astype(int)*255, average=\"macro\")\n",
    "        \n",
    "        validation_dice_original[i,cv_count] = dice_original\n",
    "        validation_dice_resized[i,cv_count] = dice_resized\n",
    "        #validation_jaccard_original[i,cv_count] = jaccard_original\n",
    "        #validation_jaccard_resized[i,cv_count] = jaccard_resized\n",
    "        \n",
    "        if i < 5:\n",
    "            plt.figure(figsize=(20,10))\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(original_img, 'gray', interpolation='none')\n",
    "            plt.imshow(original_mask/255.0, 'jet', interpolation='none', alpha=0.4)\n",
    "            plt.subplot(1,2,2)\n",
    "            # use this part to show the guessed img\n",
    "            plt.imshow(original_img, 'gray', interpolation='none')\n",
    "            plt.imshow(y_pred_original, 'jet', interpolation='none', alpha=0.4)\n",
    "            plt.show()\n",
    "    \n",
    "        dice_resized_mean = validation_dice_resized[:,cv_count].mean()\n",
    "        dice_original_mean = validation_dice_original[:,cv_count].mean()\n",
    "        #jaccard_resized_mean = validation_jaccard_resized[:,cv_count].mean()\n",
    "        #jaccard_original_mean = validation_jaccard_original[:,cv_count].mean()\n",
    "            \n",
    "        print(\"--------------------------------------\")\n",
    "        print(\"Mean validation DICE (on resized data):\", dice_resized_mean) \n",
    "        print(\"Mean validation DICE (on original data):\", dice_original_mean)\n",
    "        print(\"--------------------------------------\")\n",
    "        #print(\"Mean validation Jaccard (on resized data):\", jaccard_resized_mean) \n",
    "        #print(\"Mean validation Jaccard (on original data):\", jaccard_original_mean)\n",
    "        #print(\"--------------------------------------\")\n",
    "        # run[\"Dice Resized\"].log(dice_resized_mean)\n",
    "        # run[\"Dice Original\"].log(dice_original_mean)\n",
    "        #run[\"Jaccard Resized\"].log(jaccard_resized_mean)\n",
    "        #run[\"Jaccard Original\"].log(jaccard_original_mean)\n",
    "        runtime = time.time() - time_start \n",
    "        print('Runtime: {} sec'.format(runtime))\n",
    "        # run[\"Runtime\"] = runtime\n",
    "    f = open(\"counter.txt\", \"w\")\n",
    "    cv_count +=1\n",
    "    f.write(str(cv_count))\n",
    "    f.close()\n",
    "    print(\"cv_count is: \" + str(cv_count))\n",
    "        \n",
    "# run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_name):\n",
    "    f = os.path.join('/home/wni1717/dev/OTUMEDAI/medai2021-polypixel/input/Kvasir-SEG/images/', img_name)\n",
    "    x = cv2.imread(f, cv2.IMREAD_COLOR )\n",
    "    x = cv2.resize(x, (256,256), interpolation= cv2.INTER_LINEAR )\n",
    "    original_shape = x.shape\n",
    "    print(original_shape[1])\n",
    "    y_pred = model.predict(np.expand_dims(x,0))\n",
    "    _,y_pred_thr = cv2.threshold(y_pred[0,:,:,0]*255, 127, 255, cv2.THRESH_BINARY)\n",
    "    y_pred = (y_pred_thr/255).astype(int)\n",
    "    print(y_pred)\n",
    "    y_pred_original = cv2.resize(y_pred.astype(float), (original_shape[1],original_shape[0]), interpolation= cv2.INTER_LINEAR)\n",
    "    plt.imshow(x, 'gray', interpolation='none')\n",
    "    plt.imshow(y_pred_original, 'jet', interpolation='none', alpha=0.4)\n",
    "    plt.show()\n",
    "def original_mask(img_name):\n",
    "    f_masks = os.path.join('/home/wni1717/dev/OTUMEDAI/medai2021-polypixel/input/Kvasir-SEG/masks/', img_name)\n",
    "    f_img = os.path.join('/home/wni1717/dev/OTUMEDAI/medai2021-polypixel/input/Kvasir-SEG/images/', img_name)\n",
    "    img = cv2.imread(f_img, cv2.IMREAD_COLOR )\n",
    "    img = cv2.resize(img, (256,256), interpolation= cv2.INTER_LINEAR )\n",
    "    mask = cv2.imread(f_masks, cv2.IMREAD_COLOR )\n",
    "    mask = cv2.resize(mask, (256,256), interpolation= cv2.INTER_LINEAR )\n",
    "    plt.imshow(img, 'gray', interpolation='none')\n",
    "    plt.imshow(mask/255.0, 'jet', interpolation='none', alpha=0.4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = 'cjyzul1qggwwj07216mhiv5sy.jpg'\n",
    "predict(inp)\n",
    "original_mask(inp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "import segmentation_models as sm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from skimage.transform import rescale, resize\n",
    "from scipy.ndimage import rotate\n",
    "print(os.listdir(\"../input/\"))\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "input_path = input(\"please enter the path to the image: \")\n",
    "\n",
    "checkpoint_path = \"./Checkpoint/\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "my_model = \"efficientnetb1\"\n",
    "\n",
    "model = sm.Unet(my_model, encoder_weights='imagenet', input_shape=( 256,256, 3), classes=3, activation='sigmoid')\n",
    "model.load_weights(checkpoint_path)\n",
    "model.compile(optimizer='Adam') # changed from original\n",
    "x = cv2.imread(input_path, cv2.IMREAD_COLOR)\n",
    "x = cv2.resize(x, (256,256), interpolation= cv2.INTER_LINEAR)\n",
    "original_shape = x.shape\n",
    "y_pred = model.predict(np.expand_dims(x,0))\n",
    "_,y_pred_thr = cv2.threshold(y_pred[0,:,:,0]*255, 127, 255, cv2.THRESH_BINARY)\n",
    "y_pred = (y_pred_thr/255).astype(int)\n",
    "y_pred_original = cv2.resize(y_pred.astype(float), (original_shape[1],original_shape[0]), interpolation= cv2.INTER_LINEAR)\n",
    "plt.imshow(x, 'gray', interpolation='none')\n",
    "plt.imshow(y_pred_original, 'jet', interpolation='none', alpha=0.4)\n",
    "plt.savefig(\"/home/wni1717/dev/OTUMEDAI/OTUAILIB/models/Segmentation/output/test.png\", format = \"png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
